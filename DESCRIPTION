Package: reapr
Type: Package
Title: Reap Information from Websites
Version: 0.1.0
Date: 2019-01-15
Authors@R: c(
    person("Bob", "Rudis", email = "bob@rud.is", role = c("aut", "cre"), 
           comment = c(ORCID = "0000-0001-5670-2640"))
  )
Maintainer: Bob Rudis <bob@rud.is>
Description: There's no longer need to fear getting at the gnarly bits of web pages.
    For the vast majority of web scraping tasks, the 'rvest' package does a 
    phenomenal job providing just enough of what you need to get by. But, if you 
    want more of the details of the site you're scraping, some handy shortcuts to
    page elements in use and the ability to not have to think too hard about 
    serialization during scraping tasks, then you may be interested in reaping
    more than harvesting. Tools are provided to interact with web sites content
    and metadata more granular level than 'rvest' but at a higher level than
    'httr'/'curl'.
URL: https://gitlab.com/hrbrmstr/reapr
BugReports: https://gitlab.com/hrbrmstr/reapr/issues
NeedsCompilation: yes
Encoding: UTF-8
License: MIT + file LICENSE
Suggests:
    testthat,
    covr
Depends:
    R (>= 3.2.0)
Imports:
    httr,
    jsonlite,
    xml2,
    selectr,
    magrittr,
    curl,
    methods,
    xslt,
    stats
Roxygen: list(markdown = TRUE)
RoxygenNote: 6.1.1
